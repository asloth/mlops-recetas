services:
  model:
    build: ./
    restart: always
    networks:
        - shared_network
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    container_name: model-container
    ports:
      - "8888:8000"
    expose:
      - "8888"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ./trainmodel.py:/app/trainmodel.py
    entrypoint: >
      uvicorn trainmodel:app --host 0.0.0.0 --port 8000
  prodserver:
    build: ./
    restart: always
    networks:
        - shared_network
    container_name: prodcontainer
    ports:
      - "8899:8800"
    expose:
        - "8899"
    volumes:
      - ./evaluate.py:/app/evaluate.py
    entrypoint: >
      uvicorn evaluate:app --host 0.0.0.0 --port 8800


networks:
  shared_network:
    external: true
